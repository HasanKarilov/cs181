\documentclass{article}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{geometry}
\usepackage{enumerate}
\renewcommand{\labelenumi}{(\alph{enumi})}
\renewcommand{\labelenumii}{(\roman{enumii})}
\geometry{verbose,letterpaper,tmargin=2cm,bmargin=2cm,lmargin=2cm,rmargin=2cm}

\title{CS181: Bayesian Networks and HMMs}
\author{Danny Zhu \& Tianhui Cai}
\let\b\mathbf

\begin{document}
\maketitle

\section*{Problem 1}
\begin{center}
\begin{tikzpicture}[->,semithick,>=stealth,node distance=1.5cm,shorten >=1pt]
  \tikzstyle{state}=[circle,draw=blue!50,fill=blue!20,thick]
  \node [state] (B) {B};
  \node [state] (A) [below right of=B] {A};
  \node [state] (E) [above right of=A] {E};
  \node [state] (J) [below left of=A] {J};
  \node [state] (M) [below right of=A] {M};

  \path (B) edge (A)
        (E) edge (A)
        (A) edge (J)
            edge (M);
\end{tikzpicture}
\end{center}

\begin{enumerate}[(a)]
\item \textit{Let $S$ be the set of all nodes in the network. Using
  the idea of $d$-separation, for each pair of nodes $U,V\in S$, list
  the subsets of $S\setminus \{U,V\}$ that when observed would render
  $U,V$ independent.}

  \begin{tabular}{|c|c|}
  \hline
  Node pair $(U,V)$ & $S'\subset S\setminus \{U,V\},I(U,V|S')$ \\
  \hline
  $(B, A)$ & Impossible \\
  $(B, E)$ & $\emptyset$ \\
  $(B, J)$ & Any set containing $A$ \\
  $(B, M)$ & Any set containing $A$ \\
  $(E, A)$ & Impossible \\
  $(E, J)$ & Any set containing $A$ \\
  $(E, M)$ & Any set containing $A$ \\
  $(A, J)$ & Impossible \\
  $(A, M)$ & Impossible \\
  $(J, M)$ & Any set containing $A$ \\
  \hline
  \end{tabular}

\item \textit{Build another Bayesian network that has the same
  independence properties, using variable order $M,J,A,B,E$.}

  The process is to consider $M,J,A,B,E$ in order and for each node
  $N_i$ to find the minimal set of nodes $Pa(N_i)$ such that
  $P(N_i|N_1,\ldots,N_{i-1})=P(N_i|Pa(N_i))$.

  Doing this iteratively, $P(M)=P(M)$; $P(J|M)=P(J|M)$;
  $P(A|M,J)=P(A|M)$; $P(B|M,J,A)=P(B|A)$;
  $P(E|M,J,A,B)=P(E|A,B)$. Hence we get the following diagram:

  \begin{center}
    \begin{tikzpicture}[->,semithick,>=stealth,node distance=1.5cm,shorten >=1pt]
      \tikzstyle{state}=[circle,draw=blue!50,fill=blue!20,thick]
      \node [state] (B) {M};
      \node [state] (A) [below right of=B] {A};
      \node [state] (E) [above right of=A] {J};
      \node [state] (J) [below left of=A] {B};
      \node [state] (M) [below right of=A] {E};

      \path (B) edge (A)
      edge (E)
      (E) edge (A)
      (J) edge (M)
      (A) edge (J)
      edge (M);
    \end{tikzpicture}
  \end{center}
  This however doesn't actually give us all the same independence
  conditions as before: for instance, M and J are now never
  independent given any set of given nodes, whereas any set containing
  A previously would make them independent.  Hence there does not
  exist such a Bayes model with this ordering that has all the same
  independence conditions as the previous model.  This does, however,
  have the same dependence conditions as the previous model, by
  construction.
\item \textit{How many parameters are there in the BN in (a) and the
  BN in (b)?}

  (a): $1+1+4+2+2=10$.

  (b): $1+2+4+2+4=13$.

  \textit{Give three reasons why the BN in (a) is preferred over the
    BN in (b).}

  If we only care about dependence properties (which are preserved),
  \begin{enumerate}
  \item Fewer parameters means less storage.
  \item Fewer parameters means better sampling of data.
  \item No cycles $\rightarrow$ polytree $\rightarrow$ optimal
    elimination order.
  \end{enumerate}

\end{enumerate}

\section{Problem 2}
\begin{enumerate}[(a)]
\item \textit{Suppose the driver does not detect a cop and the traffic
  is slow.  Use variable elimination to determine}

  %  TODO: I'm not sure what variable elimination has to do with anything.

  \begin{enumerate}
  \item \textit{the probability of being late when the driver decides
    to speed and when the driver decides not to speed}

    $$P(OT=T|ST=T,SC=F,S)=\frac{\sum_C\sum_T P(OT=T,ST=T,SC=F,S,C,T)}{P(ST=T,SC=F,S)}$$
    First we calculate the denominator: $P(ST=T,SC=F,S)=P(ST=T,SC=F)$. ST and SC are 
    independent given $C$, so the denominator equals
    \begin{align*}
    &P(ST=T,SC=F|C=T)P(C=T)+P(ST=T,SC=F|C=F)P(C=F)\\
    &=0.8\cdot 0.1+0.3\cdot 0.9=0.302
    \end{align*}
    Now we evaluate the numerator $\sum_C\sum_T P(OT=T,ST=T,SC=F,S,C,T)$. 
    Rearrange terms:
    \begin{align*}
    &\sum_C P(ST=T,SC=F|C)P(C) \sum_T P(T|C,ST=T,SC=F,S)P(OT=T|T,C,ST=T,SC=F,S)\\ 
    &=\sum_C P(ST=T,SC=F|C)P(C) g_1(S,C) 
    \end{align*}
    Where $g_1(S,C)= \sum_T P(T|C,ST=T,SC=F,S)P(OT=T|T,C,ST=T,SC=F,S)$.
    \begin{align*}
    g_1(S=T,C=T)&=0.5\cdot 0.9+0.5\cdot 0=0.45\\
    g_1(S=T,C=F)&=1\cdot 0.9+0\cdot 0=0.9\\
    g_1(S=F,C=T)&=1\cdot 0.1+0\cdot 0=0.1\\
    g_1(S=F,C=F)&=1\cdot 0.1+0\cdot 0=0.1
    \end{align*}
    Rewrite the numerator as $g_2(S)$ where
    $$g_2(S)=\sum_C P(ST=T,SC=F|C)P(C)g_1(S,C)$$
    \begin{align*}
    g_2(S=T)&=0.8\cdot 0.4\cdot 0.1\cdot 0.45+0.3\cdot 0.1\cdot 0.9\cdot 0.9=0.2574\\
    g_2(S=F)&=0.4\cdot 0.4\cdot 0.1\cdot 0.1+0.4\cdot 0.1\cdot 0.9\cdot 0.1=0.0302
    \end{align*}
    The probability of being late given speeding is $1-g_2(S=T)/0.302=0.1477$.

    The probability of being late given not speeding is $1-g_2(S=F)/0.302=0.9$.

  \item \textit{the probability of getting a ticket when the driver
    decides to speed and when the driver decides not to speed}
    \begin{align*}
    &P(T=T|ST=T,SC=F,S)\\
    &=\frac{\sum_{OT}\sum_C P(OT|T=T,C,ST=T,SC=F,S)P(T|C,ST=T,SC=F,S)P(C,ST=T,SC=F,S)}{P(ST=T,SC=F,S)}
    \end{align*}
    The denominator as before is 0.302. We rearrange the numerator as follows, noting that 
    $P(OT|T=T,C,ST=T,SC=F,S)=P(OT|T=T,ST=T,SC=F)$ since $OT$ is independent of $C$ given $T$.
    \begin{align*}
    &\sum_{OT} P(OT|T=T,ST=T,SC=F,S)\sum_C P(T|C,ST=T,SC=F,S)P(ST=T,SC=F|C)P(C)\\
    &=\sum_{OT} P(OT|T=T,ST=T,SC=FS)g_1(S)
    \end{align*}
    where $g_1(S)=\sum_C P(T|C,ST=T,SC=F,S)P(ST=T,SC=F|C)P(C)$.
    \begin{align*}
    g_1(S=T)&=0.5\cdot 0.8\cdot 0.4\cdot 0.1+0\cdot 0.3\cdot 1\cdot 0.9=0.016\\
    g_2(S=F)&=0\cdot 0.8\cdot 0.4\cdot 0.1+0\cdot 0.3\cdot 1\cdot 0.9=0
    \end{align*}
    Rewrite the numerator as $g_2$, where $g_2(S)=\sum_{OT}P(OT|T=T,ST=T,SC=F,S)g_1(S)$.
    \begin{align*}
    g_2(S=T)&=0\cdot 0.016+1\cdot 0.016=0.016\\
    g_2(S=F)&=0\cdot 0+1\cdot 0=0
    \end{align*}
    Hence probability of ticket given speeding is $0.016/0.302=0.0530$.

    The probability
    of ticket given not speeding is 0. 


  \item \textit{Suppose the cost of a ticket is \$150, and the cost of
    arriving late is \$10. What is the expected utility of speeding
    and not speeding?  What would be the optimal decision?}

    Speeding: $-(150\cdot 0.0530 +10\cdot 0.1477)=-9.427$

    Not speeding: $-(150\cdot 0 +10\cdot 0.9)=-9$
    
    It is slightly better to not speed. 

  \end{enumerate}

\end{enumerate}

\section*{Problem 3}
\begin{enumerate}[(a)]
  \setcounter{enumi}2
\item
  \begin{enumerate}
  \item \emph{Define the HMM for modeling the no-momentum case in terms of
    states, observations, and the model parameters necessary.}

    There are twelve states, one for each colored square on the board.

    There are four possible observations, one for each color.

    Each state can transition to any one corresponding to an adjacent
    color with probability $\frac14$, or to itself with the remaining
    probability.

    Each state leads to the observation of the corresponding color
    with probability $.925$, and to each of the other colors with
    probability $.025$.
  \item \emph{Run \emph{\texttt{viterbi.py}} on the two datasets,
    \emph{\texttt{robot\_with\_momentumdata}} and
    \emph{\texttt{robot\_no\_momentum.data}}, to learn an HMM for each
    condition and also to infer the sequences of locations visited by
    the robot. Explore when, how, and why a hidden Markov model is
    successful or not in inferring the robot's true sequences. Give a
    brief writeup of what you found; include any observations about
    how well HMMs work on these problems and why. Think of
    explanations for the observations, and for failures, think of
    modifications to lead to success.}

    \begin{itemize}
    \item \emph{What probabilistic assumptions are we making about the nature of
      the data in using a hidden Markov model?}

    \item \emph{How well do these assumptions match the actual domain?}

    \item \emph{To what extent was, or was not, performance hurt by making such
      assumptions?}

    \end{itemize}
  \end{enumerate}
\end{enumerate}
\section*{Problem 4}
\begin{enumerate}[(a)]
\item \emph{Describe the HMM for modeling this weather problem in terms of hidden
  states, observations, and the model parameters necessary.}

  There are hidden states corresponding to states of the world that we can't
  see. They're hidden, so (at least in this case) we don't know what they are. 
  Observations are things like ``rain'', ``clouds'', ``sun'', ``fog'', etc -- 
  i.e., observable weather. 
  The model parameters necessary are the initial probabilities of being in a
  certain state, the transition probability between states, and the probability
  of getting a particular observation given a particular states. 

\item
  \begin{enumerate}
    \setcounter{enumii}2
  \item \emph{Use the two unit tests \emph{\texttt{test\_bw\_beta\_all\_equal}}
    and
    \emph{\texttt{test\_bw\_gamma\_first\_col\_equal}} to answer the following questions;
    include outputs in writeup.}

    \begin{enumerate}[(1)]
    \item \emph{Why are the betas all equal for each time step?} 

    The test gives the following output:
\begin{verbatim}
beta:
[  0.333333  0.333333  0.333333  ]
[  0.333333  0.333333  0.333333  ]
[  0.333333  0.333333  0.333333  ]
[  0.333333  0.333333  0.333333  ]
[  0.333333  0.333333  0.333333  ]
[  0.333333  0.333333  0.333333  ]
[  0.333333  0.333333  0.333333  ]
[  0.333333  0.333333  0.333333  ]
[  0.333333  0.333333  0.333333  ]
[  0.333333  0.333333  0.333333  ]
\end{verbatim}

    We remark that this is not a generally true fact, i.e. betas are not 
    necessarily all the same in all time steps for a general HMM. 
    But in this particular case they are. The model this is run on has three states
    and a transition matrix in which every value is equal, i.e. the probabilities
    of going from any state $a$ to any state $b$ are all equal. 
    Additionally, the observation model is such that the probability of any
    given observation is equal, if we don't know anything about what 
    state it's in, i.e. $P(O_t=o_t)=P(O_T=o_t')$. 

    Now we look at the equation for $\beta$. 
    $$\beta(x_t)=\sum_{x_{t+1}} P(X_{t+1}=x_{t+1}|X_t=x_t)P(O_{t+1}=o_{t+1}|X_{t+1}=x_{t+1})\beta (x_{t+1})$$
    The $\beta(x_T)$'s are initialized to all be equal, so by induction (we're
    hypothesizing that the $\beta(x_t)$'s are the same, always) we can pull that
    term out of the sum. Furthermore, since the transition matrix has equal
    entries, the first term $P(X_{t+1}=x_{t+1}|X_t=x_t)$ is also a constant
    that we can pull out of the sum. Then we're left with some constants times
    $\sum_{x_{t+1}} P(O_{t+1}=o_{t+1}|X_{t+1}=x_{t+1})$; by marginalization
    and the fact that $P(O_t=o_t)=P(O_t=o_t')$, this part is also equal across
    all $x_i$. Hence we have that each $\beta(x_i)$ at any given time period
    is just the product of three constants which are the same over all $x_i$.
    
    
    \item \emph{Why are the gamma values for the first state the same for all time periods?}

    Again, this does not appear to be a generally true fact. The outcomes
    we get from running on this simple model are as follows:

\begin{verbatim}
gamma:
[  0.333333  0.500000  0.166667  ]
[  0.333333  0.500000  0.166667  ]
[  0.333333  0.500000  0.166667  ]
[  0.333333  0.500000  0.166667  ]
[  0.333333  0.500000  0.166667  ]
[  0.333333  0.500000  0.166667  ]
[  0.333333  0.166667  0.500000  ]
[  0.333333  0.500000  0.166667  ]
[  0.333333  0.166667  0.500000  ]
[  0.333333  0.166667  0.500000  ]
[  0.333333  0.166667  0.500000  ]
[  0.333333  0.166667  0.500000  ]
\end{verbatim}

    In lecture we defined $\gamma_t(s)=P(X_t=s|O_1=o_1,\ldots,O_T=o_t)$. 
    Intuitively it makes sense that $\gamma_t(s)$ are all equal, i.e. that
    the probability of the HMM being at the first state at some time $t$,
    given all observations, is the same: the transition matrix has equal 
    values everywhere, so only the current $X_t$ matters rather than the
    entire sequence, and $P(O=1|X_t=1)=P(O=0|X_t=1)$, i.e. all outcomes
    are equally likely in the first state, and also they are equally likely
    if they are not in the first state. So if $\gamma_t(s)$ only depends
    on how likely we are to observe some $o_t$, and if all outcomes are
    equally likely given $x_1$ and given not-$x_1$, intuitively how likely 
    the $t$th state is $x_1$ should all be the same. 

    More rigorously, we can take a look at the $\alpha$ values as well, 
    since $\gamma_t(s)=\frac{\alpha_t(s)\beta_t(s)}{\sum_{s'}\alpha_t(s')\beta_t(s')}$:
    since $\beta_t(s')$ is always 1/3 for all $s'$, we then just have
    $$\gamma_t(s)=\frac{\alpha_t(s)}{\sum_{s'}\alpha(t,s')}$$
    Considering the recursive formula for $\alpha$, 
    $$\alpha_t(x_t)=P(o_t|x_t)\sum_{x_{t-1}}P(x_t|x_{t-1})\alpha(x_{t-1})$$ we
    see that again we pull $P(x_t|x_{t-1})$ out of the sum as it is
    equal everywhere. It suffices to show $\alpha_t(1)/(\alpha_t(2)+\alpha_t(3))$
    remains constant, i.e. 
    $$\frac{P(o_t|1)\sum \alpha(x_{t-1})}{P(o_t|X_t=2)\sum\alpha(x_{t-1})+P(o_t|X_t=3)\sum \alpha(x_{t-1})}=\frac{P(o_t|X_t=1)}{P(o_t|X_t=2)+P(o_t|X_t=3)}$$
    This remains constant as $P(O_t=1|X_t=1)=P(O_t=0|X_t=1)$, and the other two 
    always sum up to the same thing ($P(O_t=0|X_t=2)=P(O_t=1|X_t=3)$ and vice versa). 

    \end{enumerate}

  \item \emph{Alpha and beta values get small for long sequences. If you look at the
    \emph{\texttt{get\_alpha}} function, you can see that there is normalization code.
    Why is the sum of the logs of the normalization factors the log likelihood of
    the returned observation sequence?}

    $\log(a\cdot b)=\log(a)+\log(b)$. Taking logs of small alpha and beta values
    make them less prone to encoding error.

  \end{enumerate}

\item
  \begin{enumerate}
  \item \emph{Run \texttt{\emph{classify.py}} on each data set to learn an HMM
    for each city from the training data and use them to classify the test data.
    Vary the number of hidden states from 1 to 6 and plot the final classification
    accuracy vs the number of hidden states.}

  \item \emph{Plot $\log(P(D|\Theta))$ for training the model for Boston with
    varying numbers of hidden states. Do you see any patterns?}

  \item \emph{By looking at the data and the learned models, try to explain your
    results. When do more hidden states help? When are they not needed? What is
    it about the observations that makes more states unnecessary?}

  \item \emph{The data was generated synthetically. How many hidden states do you
    think were in our generating model? Why?}

  \end{enumerate}
\end{enumerate}
\end{document}
