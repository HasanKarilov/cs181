==Draft of strategy to be implemented==

Caveat:
- There's a lot of stuff here, choose which ones we'll implement?
- We need to implement at least two different methods to solve two
  different problems. 

Decisions to be made:
1 whether we think a plant is nutritious
  a given an observation
  b given location
2 whether to request observation of plant
3 whether to eat plant
4 where to go next

We're given that the distributions for plant image generation and 
world-generation are fixed between the games we get and the actual
tests.

Hence, of the decisions to be made, (1) and (4) can be learned off-line, 
while (2) is learned on-line, as parameters can change. (3) is kind of a duh.

Factors that we know that we can consider:
- current location, and 
- locations already visited (or a subset thereof), and
- whether there were good plants at those locations
- energy left
- number of (nutritious/poisonous) plants eaten/observed

1a  Given an observation, determine whether a plant is nutritious or poisonous
  - we also want an estimation of how confident we are. On a crude level 
    we can just use success rate, but it would be better if we knew confidence
    PER observation
  - IMPLEMENTATION OPTIONS: probably we should use a neural network. 
    (SVMs seem hard and dtrees are wrong.)
  - Since this is learned off-line, do testing and validation and save
    the resulting neural network that classifies best. 
  - problem with neural nets: getting confidence estimates will be from
    activation of output notes, which aren't actually confidence estimates. 
      - TODO: think of something clever. 
      - possibly histogram to find relation between 
        actual accuracy vs neural net activation, i.e. P(o|s). 
        (This will take a lot of runs / training)

1b  Given a plant in a certain place, how likely is it to be nutritious
  - It would be nice to have a prior on how likely a plant in a given place is 
    good to eat. The world is unfortunately infinitely big, so hypotheses like
    "higher density of good plants at (5,10)" are difficult to test, as there
    are infinitely many of them. 
  - But we can learn this off-line. 
  - TODO: think of something clever.
  - Possible hypothesis: nutritious plants clump together, or poisonous plants
    are spaced apart. 
  - At worst, we should be able to find the probability that a plant in general
    is poisonous or nutritious (i.e. count.) 

2   Decide whether or not to observe
  - Learn on-line, as parameters change. 

  - Intuition: if you are almost out of energy, and a plant appears nutritious
    after one observation, you're more likely to eat it anyway, i.e. accept
    fewer observations as okay. 
  - But if you get ambiguous results, you should decide to not eat as a default?
    I.e set some sort of threshold (which we would train), i.e. when you decide 
    for sure whether or not it's poisonous then you just eat or leave it alone. 

  - States: { energy left, number of observations, aggregate confidence: nutritious - poisonous readings }
  - Actions: { observe, not observe }
  - Rewards: amount of life given such an action??? This seems like it would use Q-learning...

  - Problem: aggregate confidence is tricky to calibrate. 
  - Probably we do this once we answer the other problems, because then we choose whether to
    eat or not eat on a fixed algorithm.

3   Decide whether or not to eat
  - This just happens: we use the result we get once we decide to stop observing
    possibly in addition to a prior. (????)
  - Maximize expected utility: max_a \sum_s P(o|s)P(s)R(s,a)
    P(o|s) is from an aggregate of confidence estimates (calibrated??)
    P(s) is the prior on how likely a plant is to be poisonous or
    nutritious (locationwise hopefully; if not --  
    (# nutritious)/(# plants total observed) from off-line learning?)
    R(s,a) is defined given game parameters. 

4   Where to move next
  - Infinite world means it's harder to figure out distributions in which they
    generally put more nutritious plants in one area, etc. 
  - It's possible that good/bad plants are clustered together. Then we could
    try doing an MDP where states = {has just seen (nutritions/poisonous) plant in some set of neighboring locations x energy left}
    and actions = {directions}. 


ISSUES
* I feel like we haven't used clustering. At all. 
* Maybe we should use, like, Dyna-Q or other weird things like that






